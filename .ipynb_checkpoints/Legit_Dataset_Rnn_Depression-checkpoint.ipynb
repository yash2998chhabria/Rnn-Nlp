{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "sLt5uqskqqpE",
    "outputId": "c7bc2b3f-c092-4264-d5d6-1a429aab0d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed: invalid oauth code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed: invalid oauth code"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P-qOiwcqreoT"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd \n",
    "\n",
    "df_cols= [\"id\",\"text_list\",\"condition\"]\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SNe8_TGRyfxw"
   },
   "outputs": [],
   "source": [
    "\n",
    "filenames = glob.glob(\"reddit-training-ready-to-share/positive_examples_anonymous/train_subject[0-9]*.xml\")  # change the pattern to match your case\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as content:\n",
    "        tree = ET.parse(content)\n",
    "        o_id = tree.find('ID').text\n",
    "        lst_jugador = tree.findall('WRITING/TEXT')\n",
    "        o_txtlst = \"\"\n",
    "        for comment in lst_jugador:\n",
    "          o_txtlst += comment.text\n",
    "    rows.append({\"id\":o_id, \"text_list\":o_txtlst, \"condition\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lP_S2mb_BbZ-"
   },
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame(rows,columns= df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J0wv9aATD4bl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tLifRqwtIlyC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_list</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>train_subject933</td>\n",
       "      <td>I try to buy swim shorts that reach mid thigh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>train_subject6760</td>\n",
       "      <td>Swim. Dance.   At a dinner party at  house ov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>train_subject7925</td>\n",
       "      <td>so what do you do when you find out your bf c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>train_subject7367</td>\n",
       "      <td>What restaurant? I live in phoenix.  What is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>train_subject5723</td>\n",
       "      <td>thank you for your kind words  Could you plea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>train_subject8843</td>\n",
       "      <td>I sorry to hear that, it sounds like things a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>train_subject3902</td>\n",
       "      <td>Something something, \"oh I can't believe you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>train_subject4493</td>\n",
       "      <td>Coming off of them was hell because you quit ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>train_subject2871</td>\n",
       "      <td>I um, had an abortion earlier this year. I ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>train_subject4630</td>\n",
       "      <td>I liked it :)  I've played that mission dozen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_subject2252</td>\n",
       "      <td>Not Really...it just wasn't as impactful, or ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>train_subject9951</td>\n",
       "      <td>To be fair, their account is 14 hours old.   ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>train_subject5537</td>\n",
       "      <td>Brilliant, thanks!    I'm playing through thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>train_subject6101</td>\n",
       "      <td>I have this picture as gelaskin on my old pho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>train_subject7181</td>\n",
       "      <td>Data of my boyfriend:\\n\\n* Age: 22\\n* male\\n*...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>train_subject7142</td>\n",
       "      <td>I have the same feelings ,I don't see myself ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_subject1361</td>\n",
       "      <td>Mine were very useful. I was initially assess...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>train_subject9001</td>\n",
       "      <td>Same with my mom. Also anything on adult swim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_subject1457</td>\n",
       "      <td>Washington it is. Born and raised. Now, I mus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>train_subject7930</td>\n",
       "      <td>Blue Yian Kut-Ku (Lv. 90)\\nWeapon Bias SA, CB...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                          text_list  \\\n",
       "76   train_subject933   I try to buy swim shorts that reach mid thigh...   \n",
       "49  train_subject6760   Swim. Dance.   At a dinner party at  house ov...   \n",
       "63  train_subject7925   so what do you do when you find out your bf c...   \n",
       "58  train_subject7367   What restaurant? I live in phoenix.  What is ...   \n",
       "42  train_subject5723   thank you for your kind words  Could you plea...   \n",
       "70  train_subject8843   I sorry to hear that, it sounds like things a...   \n",
       "31  train_subject3902   Something something, \"oh I can't believe you ...   \n",
       "35  train_subject4493   Coming off of them was hell because you quit ...   \n",
       "24  train_subject2871   I um, had an abortion earlier this year. I ha...   \n",
       "36  train_subject4630   I liked it :)  I've played that mission dozen...   \n",
       "18  train_subject2252   Not Really...it just wasn't as impactful, or ...   \n",
       "82  train_subject9951   To be fair, their account is 14 hours old.   ...   \n",
       "40  train_subject5537   Brilliant, thanks!    I'm playing through thi...   \n",
       "44  train_subject6101   I have this picture as gelaskin on my old pho...   \n",
       "55  train_subject7181   Data of my boyfriend:\\n\\n* Age: 22\\n* male\\n*...   \n",
       "53  train_subject7142   I have the same feelings ,I don't see myself ...   \n",
       "7   train_subject1361   Mine were very useful. I was initially assess...   \n",
       "74  train_subject9001   Same with my mom. Also anything on adult swim...   \n",
       "8   train_subject1457   Washington it is. Born and raised. Now, I mus...   \n",
       "64  train_subject7930   Blue Yian Kut-Ku (Lv. 90)\\nWeapon Bias SA, CB...   \n",
       "\n",
       "    condition  \n",
       "76          1  \n",
       "49          1  \n",
       "63          1  \n",
       "58          1  \n",
       "42          1  \n",
       "70          1  \n",
       "31          1  \n",
       "35          1  \n",
       "24          1  \n",
       "36          1  \n",
       "18          1  \n",
       "82          1  \n",
       "40          1  \n",
       "44          1  \n",
       "55          1  \n",
       "53          1  \n",
       "7           1  \n",
       "74          1  \n",
       "8           1  \n",
       "64          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr4Uqkp3NrB9"
   },
   "source": [
    "Negative dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8Y9Vr9YyJMlc"
   },
   "outputs": [],
   "source": [
    "df_cols= [\"id\",\"text_list\",\"condition\"]\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MiaaDhhZNurG"
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"reddit-training-ready-to-share/negative_examples_anonymous/train_subject[0-9]*.xml\")  # change the pattern to match your case\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as content:\n",
    "        tree = ET.parse(content)\n",
    "        o_id = tree.find('ID').text\n",
    "        lst_jugador = tree.findall('WRITING/TEXT')\n",
    "        o_txtlst = \"\"\n",
    "        for comment in lst_jugador:\n",
    "          o_txtlst += comment.text\n",
    "    rows.append({\"id\":o_id, \"text_list\":o_txtlst, \"condition\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DRDdrDOjN2g1"
   },
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(rows,columns= df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3vbiSJSlN680"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BIwvMxWhN9QA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_list</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>train_subject6584</td>\n",
       "      <td>hotair.com is full of hot air.  Walker was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>train_subject3687</td>\n",
       "      <td>I liked dart vapor in garland  Sorry Sir, we ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>train_subject5287</td>\n",
       "      <td>What's the game plan, Kevin? It w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>train_subject9242</td>\n",
       "      <td>Closeminded much?  Please give me calcium mr ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>train_subject9554</td>\n",
       "      <td>Ballsy.... but not that funny.  Much useful...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>train_subject8542</td>\n",
       "      <td>Ever had that feeling that somethings watchin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>train_subject9956</td>\n",
       "      <td>I'll punch your face... in the face   http://...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>train_subject8961</td>\n",
       "      <td>Most Beatles songs.   Knocked his lights ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>train_subject5763</td>\n",
       "      <td>Steve Buscemi, he looks lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>train_subject2006</td>\n",
       "      <td>Meanwhile, in 'MURICA, women don't have the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>train_subject1939</td>\n",
       "      <td>Modern utopias tend to be different becaus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>train_subject9546</td>\n",
       "      <td>May 2nd. Just me and The People's Champ The R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>train_subject4565</td>\n",
       "      <td>To be fair, there's a spoiler warning just be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>train_subject4999</td>\n",
       "      <td>Sure!  I used Alton Brown's recipe http://w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>train_subject4010</td>\n",
       "      <td>Thanks! Don't worry though - I'm totally wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>train_subject3651</td>\n",
       "      <td>Original Study: http://www.pnas.org/content...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>train_subject7287</td>\n",
       "      <td>I literally love you...  They actually both l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>train_subject1519</td>\n",
       "      <td>Skit wasnt funny. It was just irritating to w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>train_subject2521</td>\n",
       "      <td>Baby steps. Sounds like you're doing things t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>train_subject9154</td>\n",
       "      <td>Yes there are many names for it. Circle of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          text_list  \\\n",
       "241  train_subject6584     hotair.com is full of hot air.  Walker was ...   \n",
       "103  train_subject3687   I liked dart vapor in garland  Sorry Sir, we ...   \n",
       "184  train_subject5287               What's the game plan, Kevin? It w...   \n",
       "363  train_subject9242   Closeminded much?  Please give me calcium mr ...   \n",
       "381  train_subject9554     Ballsy.... but not that funny.  Much useful...   \n",
       "326  train_subject8542   Ever had that feeling that somethings watchin...   \n",
       "399  train_subject9956   I'll punch your face... in the face   http://...   \n",
       "344  train_subject8961       Most Beatles songs.   Knocked his lights ...   \n",
       "211  train_subject5763                     Steve Buscemi, he looks lik...   \n",
       "44   train_subject2006     Meanwhile, in 'MURICA, women don't have the...   \n",
       "42   train_subject1939      Modern utopias tend to be different becaus...   \n",
       "379  train_subject9546   May 2nd. Just me and The People's Champ The R...   \n",
       "149  train_subject4565   To be fair, there's a spoiler warning just be...   \n",
       "168  train_subject4999     Sure!  I used Alton Brown's recipe http://w...   \n",
       "115  train_subject4010     Thanks! Don't worry though - I'm totally wi...   \n",
       "100  train_subject3651     Original Study: http://www.pnas.org/content...   \n",
       "270  train_subject7287   I literally love you...  They actually both l...   \n",
       "22   train_subject1519   Skit wasnt funny. It was just irritating to w...   \n",
       "61   train_subject2521   Baby steps. Sounds like you're doing things t...   \n",
       "359  train_subject9154     Yes there are many names for it. Circle of ...   \n",
       "\n",
       "     condition  \n",
       "241          0  \n",
       "103          0  \n",
       "184          0  \n",
       "363          0  \n",
       "381          0  \n",
       "326          0  \n",
       "399          0  \n",
       "344          0  \n",
       "211          0  \n",
       "44           0  \n",
       "42           0  \n",
       "379          0  \n",
       "149          0  \n",
       "168          0  \n",
       "115          0  \n",
       "100          0  \n",
       "270          0  \n",
       "22           0  \n",
       "61           0  \n",
       "359          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Iq8qFDZ0OzTf"
   },
   "outputs": [],
   "source": [
    "Combined_df = pd.concat([neg_df,pos_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZB6DYgxGPXU0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ahqbKlN3PkKR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eZThnbTKPuns"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mFH3CJZaPxfP"
   },
   "outputs": [],
   "source": [
    "Combined_df = Combined_df.sample(len(Combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "k6-NcyohQAez"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_list</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>train_subject2339</td>\n",
       "      <td>It looks like you are in a turn, couldn't tel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>train_subject3540</td>\n",
       "      <td>This sounds familiar from back in the day, I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>train_subject5439</td>\n",
       "      <td>This is Amy. You are right!  Finding customer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>train_subject6309</td>\n",
       "      <td>I dream of being able of turning my house int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>train_subject4353</td>\n",
       "      <td>Bruiser Shyv. Generally 2 offensive items.  H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>train_subject9061</td>\n",
       "      <td>Except they did before the edit, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>train_subject3657</td>\n",
       "      <td>I personally have never viewed any content fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>train_subject5649</td>\n",
       "      <td>Really love her stomach piercings, they flow ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>train_subject4831</td>\n",
       "      <td>Lmao! it will end when we have the technology...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>train_subject9201</td>\n",
       "      <td>I drybrushed white over the gesso, *then* p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          text_list  \\\n",
       "51   train_subject2339   It looks like you are in a turn, couldn't tel...   \n",
       "95   train_subject3540   This sounds familiar from back in the day, I ...   \n",
       "193  train_subject5439   This is Amy. You are right!  Finding customer...   \n",
       "229  train_subject6309   I dream of being able of turning my house int...   \n",
       "132  train_subject4353   Bruiser Shyv. Generally 2 offensive items.  H...   \n",
       "354  train_subject9061               Except they did before the edit, ...   \n",
       "101  train_subject3657   I personally have never viewed any content fo...   \n",
       "41   train_subject5649   Really love her stomach piercings, they flow ...   \n",
       "159  train_subject4831   Lmao! it will end when we have the technology...   \n",
       "361  train_subject9201     I drybrushed white over the gesso, *then* p...   \n",
       "\n",
       "     condition  \n",
       "51           0  \n",
       "95           0  \n",
       "193          0  \n",
       "229          0  \n",
       "132          0  \n",
       "354          0  \n",
       "101          0  \n",
       "41           1  \n",
       "159          0  \n",
       "361          0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combined_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "W6mee4IlQC1d"
   },
   "outputs": [],
   "source": [
    "Combined_df.to_csv(\"reddit-training-ready-to-share/Uscdata_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_wIiO9iQ-rk"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6kuaIyxSrd5"
   },
   "outputs": [],
   "source": [
    "Combined_df.drop(['id'], axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNE1JaYZSRdW"
   },
   "outputs": [],
   "source": [
    "tweets = Combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcJ5VdYeSc-U"
   },
   "outputs": [],
   "source": [
    "tweets = tweets.rename(index = str, columns = {'text_list': 'SentimentText', 'condition': 'Sentiment'})\n",
    "\n",
    "tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygx8GWnyS204"
   },
   "outputs": [],
   "source": [
    "tweets=tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uLs6zS3TCum"
   },
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDdMVfH_TEU2"
   },
   "outputs": [],
   "source": [
    "tweets['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Lp7hd6VTGUT"
   },
   "outputs": [],
   "source": [
    "tweets.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBLFc21cTJgw"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax = sns.barplot(x=tweets.Sentiment.unique(), y=tweets.Sentiment.value_counts())\n",
    "\n",
    "ax.set(xlabel='Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "FNaxxXi4TLYV",
    "outputId": "d41b123e-4029-42d5-89dc-47ee73079508"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ac050abad92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(tweets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGdoOKDBTOT_"
   },
   "outputs": [],
   "source": [
    "train.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pl51r24BTP-D"
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "0C7qfvrgTSNX",
    "outputId": "649b795c-6c9c-43b4-e2f4-ff6a853bed7d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-df61f6fdc1ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/REDDIT DATASET/reddit-training-ready-to-share/train_tweets.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/REDDIT DATASET/reddit-training-ready-to-share/test_tweets.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train.to_csv('/content/drive/MyDrive/REDDIT DATASET/reddit-training-ready-to-share/train_tweets.csv', index=False)\n",
    "test.to_csv('/content/drive/MyDrive/REDDIT DATASET/reddit-training-ready-to-share/test_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jTPKpt1eTjNv"
   },
   "outputs": [],
   "source": [
    "def tweet_clean(text):\n",
    "    \n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) \n",
    "    text = re.sub(r'https?:/\\/\\S+', ' ', text) \n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "43cw_j19TldK",
    "outputId": "d3cf6550-a77a-4194-d4d7-b7bf8e378b34"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5e4ace05000c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tagger'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(s): \n",
    "    return [w.text.lower() for w in nlp(tweet_clean(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "yYxhP_yiTm4p",
    "outputId": "f69b32f2-2828-499a-e240-a41dcd5c8e1e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3c8d9bc25211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchtext' is not defined"
     ]
    }
   ],
   "source": [
    "TEXT = torchtext.data.Field(tokenize = tokenizer)\n",
    "\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6-ZJXozToaX"
   },
   "outputs": [],
   "source": [
    "datafields = [('SentimentText', TEXT),('Sentiment', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "j-jKydPgTpp8",
    "outputId": "a1940ec7-370b-4db1-db0b-355862448edf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c5690410b863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trn, tst = torchtext.data.TabularDataset.splits(path = '/content/drive/MyDrive/REDDIT DATASET/reddit-training-ready-to-share/', \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                 \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train_tweets.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                 \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_tweets.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                 \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                 \u001b[0mskip_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchtext' is not defined"
     ]
    }
   ],
   "source": [
    "trn, tst = torchtext.data.TabularDataset.splits(path = '/content/drive/MyDrive/REDDIT DATASET/reddit-training-ready-to-share/', \n",
    "                                                train = 'train_tweets.csv',\n",
    "                                                test = 'test_tweets.csv',    \n",
    "                                                format = 'csv',\n",
    "                                                skip_header = True,\n",
    "                                                fields = datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTts4nGyXM12"
   },
   "source": [
    "TO FIX CSV FILE LIMIT ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GgINJNmTxr7",
    "outputId": "01f90623-de6f-43e0-feb8-be7de68c27fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import ctypes as ct\n",
    "csv.field_size_limit(int(ct.c_ulong(-1).value // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHXiDjGyUze8",
    "outputId": "ffdefc69-6811-4498-f6de-2673895fcfe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import ctypes as ct\n",
    "csv.field_size_limit(int(ct.c_ulong(-1).value // 2))\n",
    "limit1 = csv.field_size_limit()\n",
    "limit1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "k8YOsXXfUaA7",
    "outputId": "bf87393a-aea0-4501-d571-a758cf4683e0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'0x7FFFFFFFFFFFFFFF'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"0x{0:016X}\".format(limit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "fP2wSkH4Ud6Y",
    "outputId": "52f6a571-2002-4242-8552-2f7b79db3a85"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2ce5b057a590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of training examples: {len(trn)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of testing examples: {len(tst)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trn' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(trn)}')\n",
    "print(f'Number of testing examples: {len(tst)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "UrpKD6gPXSen",
    "outputId": "ae4457ea-1f8d-419c-b8a2-a56fffa2cde5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fb82b74e43b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trn' is not defined"
     ]
    }
   ],
   "source": [
    "vars(trn.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nI4fo11EXUOs"
   },
   "outputs": [],
   "source": [
    "vars(tst.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1801BVjwXYkc"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, max_size=25000,\n",
    "                 vectors=\"glove.6B.100d\",\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "hg4nw_87XblW",
    "outputId": "25bdd16e-5256-4cec-a9d1-b4c36366e1b2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-193b02b2a7bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQmXzOXzYkCr"
   },
   "outputs": [],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCLfQBVoYlLK"
   },
   "outputs": [],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "sxEGUvCSYmr8",
    "outputId": "1a4790cc-1994-4f85-f76c-b7311e7e96c5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-638fd96879ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0msort_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentimentText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 sort_within_batch=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchtext' is not defined"
     ]
    }
   ],
   "source": [
    "train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
    "                                (trn, tst),\n",
    "                                batch_size = 64,\n",
    "                                sort_key=lambda x: len(x.SentimentText),\n",
    "                                sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8RXv0nVZXNr"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
    "                 output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
    "                           bidirectional = bidirectional, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "       \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "ULCxJ4ddZbmw",
    "outputId": "e62b8acf-0065-47f9-81c7-0cf0bd26514f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e1ceeb22c830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "hidden_dim = 20\n",
    "output_dim = 1\n",
    "\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNhgnGmyZdYY"
   },
   "outputs": [],
   "source": [
    "model = RNN(input_dim, \n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            output_dim, \n",
    "            n_layers, \n",
    "            bidirectional, \n",
    "            dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYkqLQ25Zg93"
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4yKgmT7ZiyH"
   },
   "outputs": [],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQcWSrmXZlwo"
   },
   "outputs": [],
   "source": [
    "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCfixoaHZone"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0005)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuZtz6oTZqbC"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.Sentiment).float() \n",
    "        \n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPuS4Tc-Ztj1"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "     \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in test_iterator:\n",
    "\n",
    "            predictions = model(batch.SentimentText).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions, batch.Sentiment)\n",
    "\n",
    "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "            correct = (rounded_preds == batch.Sentiment).float() \n",
    "            \n",
    "            acc = correct.sum()/len(correct)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "    test_loss = epoch_loss / len(test_iterator)\n",
    "    test_acc = epoch_acc / len(test_iterator)\n",
    "      \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n",
    "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQkeffG-Zxnk"
   },
   "outputs": [],
   "source": [
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in test_iterator:\n",
    "\n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "\n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.Sentiment).float() \n",
    "        \n",
    "        acc = correct.sum()/len(correct)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "test_loss = epoch_loss / len(test_iterator)\n",
    "test_acc = epoch_acc / len(test_iterator)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Epf_A8P8qCY9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Legit Dataset Rnn Depression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
