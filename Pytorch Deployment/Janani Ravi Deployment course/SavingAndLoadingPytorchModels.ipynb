{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (1.17.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.1\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>12.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.29</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>12.37</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.10</td>\n",
       "      <td>18.5</td>\n",
       "      <td>88</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.77</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.38</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.24</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.16</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "130      3    12.86        1.35  2.32               18.0        122   \n",
       "1        1    13.20        1.78  2.14               11.2        100   \n",
       "98       2    12.37        1.07  2.10               18.5         88   \n",
       "102      2    12.34        2.45  2.46               21.0         98   \n",
       "85       2    12.67        0.98  2.24               18.0         99   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "130           1.51        1.25                  0.21             0.94   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "98            3.52        3.75                  0.24             1.95   \n",
       "102           2.56        2.11                  0.34             1.31   \n",
       "85            2.20        1.94                  0.30             1.46   \n",
       "\n",
       "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "130             4.10  0.76                          1.29      630  \n",
       "1               4.38  1.05                          3.40     1050  \n",
       "98              4.50  1.04                          2.77      660  \n",
       "102             2.80  0.80                          3.38      438  \n",
       "85              2.62  1.23                          3.16      450  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = pd.read_csv('data/Wine.csv', names=columns)\n",
    "wine_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the data\n",
    "* Removing all the records having NaN values\n",
    "* Convert target values to number using label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.38</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.96</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>12.17</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.53</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2.95</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.23</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>11.84</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.23</td>\n",
       "      <td>18.0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.52</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>17.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.93</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>13.41</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.12</td>\n",
       "      <td>18.8</td>\n",
       "      <td>90</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>13.72</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.7</td>\n",
       "      <td>108</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.04</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>13.76</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>19.5</td>\n",
       "      <td>132</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "102      1    12.34        2.45  2.46               21.0         98   \n",
       "117      1    12.42        1.61  2.19               22.5        108   \n",
       "64       1    12.17        1.45  2.53               19.0        104   \n",
       "37       0    13.05        1.65  2.55               18.0         98   \n",
       "7        0    14.06        2.15  2.61               17.6        121   \n",
       "77       1    11.84        2.89  2.23               18.0        112   \n",
       "68       1    13.34        0.94  2.36               17.0        110   \n",
       "41       0    13.41        3.84  2.12               18.8         90   \n",
       "58       0    13.72        1.43  2.50               16.7        108   \n",
       "33       0    13.76        1.53  2.70               19.5        132   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "102           2.56        2.11                  0.34             1.31   \n",
       "117           2.00        2.09                  0.34             1.61   \n",
       "64            1.89        1.75                  0.45             1.03   \n",
       "37            2.45        2.43                  0.29             1.44   \n",
       "7             2.60        2.51                  0.31             1.25   \n",
       "77            1.72        1.32                  0.43             0.95   \n",
       "68            2.53        1.30                  0.55             0.42   \n",
       "41            2.45        2.68                  0.27             1.48   \n",
       "58            3.40        3.67                  0.19             2.04   \n",
       "33            2.95        2.74                  0.50             1.35   \n",
       "\n",
       "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "102             2.80  0.80                          3.38      438  \n",
       "117             2.06  1.06                          2.96      345  \n",
       "64              2.95  1.45                          2.23      355  \n",
       "37              4.25  1.12                          2.51     1105  \n",
       "7               5.05  1.06                          3.58     1295  \n",
       "77              2.65  0.96                          2.52      500  \n",
       "68              3.17  1.02                          1.93      750  \n",
       "41              4.28  0.91                          3.00     1035  \n",
       "58              6.80  0.89                          2.87     1285  \n",
       "33              5.40  1.25                          3.00     1235  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "wine_data['Class'] = le.fit_transform(wine_data['Class'])\n",
    "\n",
    "wine_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.to_csv('data/wine_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting Features\n",
    "* Create training and test data using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>12.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.12</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.87</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>11.76</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.92</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.50</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "80     12.00        0.92  2.00               19.0         86           2.42   \n",
       "63     12.37        1.13  2.16               19.0         87           3.50   \n",
       "13     14.75        1.73  2.39               11.4         91           3.10   \n",
       "112    11.76        2.68  2.92               20.0        103           1.75   \n",
       "174    13.40        3.91  2.48               23.0        102           1.80   \n",
       "\n",
       "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "80         2.26                  0.30             1.43             2.50  1.38   \n",
       "63         3.10                  0.19             1.87             4.45  1.22   \n",
       "13         3.69                  0.43             2.81             5.40  1.25   \n",
       "112        2.03                  0.60             1.05             3.80  1.23   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "\n",
       "     OD280/OD315 of diluted wines  Proline  \n",
       "80                           3.12      278  \n",
       "63                           2.87      420  \n",
       "13                           2.73     1150  \n",
       "112                          2.50      607  \n",
       "174                          1.56      750  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_features = wine_data.drop('Class', axis = 1)\n",
    "wine_features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class\n",
       "25       0\n",
       "27       0\n",
       "132      2\n",
       "164      2\n",
       "90       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_target = wine_data[['Class']]\n",
    "wine_target.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_test, Y_train, y_test = train_test_split(wine_features,\n",
    "                                                    wine_target,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106, 13), (106, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ = torch.from_numpy(X_train.values).float()\n",
    "Xtest_ = torch.from_numpy(x_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106, 13])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y parameters have shape 106 X 1 but we need those in shape 1 X 106<br>\n",
    "Our loss function doesnt support multi-target, our target should be 1D Tensor\n",
    "i.e 1 row containing all the labels<br>\n",
    "\n",
    "<b>view: </b>with view we reshape the tensor <br>\n",
    "view with -1<br>\n",
    "If there is any situation that you don't know how many columns you want but are sure of the number of rows then you can mention it as -1, or vice-versa (You can extend this to tensors with more dimensions. Only one of the axis value can be -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_ = torch.from_numpy(Y_train.values).view(1,-1)[0]\n",
    "Ytest_ = torch.from_numpy(y_test.values).view(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 13 features therefore input size is 13 and we want 3 discrete outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\n",
    "output_size = 3\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a neural network class from which to create our model\n",
    "\n",
    "We create a class named Net which inherits nn.Module(Base class for all neural network modules.)<br>\n",
    "\n",
    "<b>super :</b> This is calling the \\__init__() method of the parent class(nn.Module)\n",
    "\n",
    "<b>fc1 to fc3 :</b>  Applies a linear transformation to the incoming data: y=Wx+b<br>\n",
    "Parameters :<br>\n",
    "in_features – size of each input sample<br>\n",
    "out_features – size of each output sample<br>\n",
    "bias – If set to False, the layer will not learn an additive bias. Default: True<br>\n",
    "\n",
    "<b>Sigmoid : </b>Applies the element-wise function Sigmoid(x)= 1 / (1+exp(−x))\n",
    "\n",
    "<b>log_softmax :</b>\n",
    "Softmax applies the Softmax() function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range (0,1) and sum to 1<br>\n",
    "While mathematically equivalent to log(softmax(x)), doing these two operations separately is slower, and numerically unstable. This function uses an alternative formulation to compute the output and gradient correctly.<br>\n",
    "Parameters:<br>\n",
    "dim(int) – A dimension along which Softmax will be computed (so every slice along dim will sum to 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = torch.sigmoid((self.fc1(X)))\n",
    "        X = torch.sigmoid(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer.zero_grad:\n",
    "* Before the backward pass, use the optimizer object to zero all of the gradients for the variables it will update (which are the learnable weights of the model)\n",
    "\n",
    "Foward Pass:\n",
    "* Predicting Y with input data X\n",
    "\n",
    "Finding training Loss:\n",
    "* Finding difference between Y_train_tensor and Y_pred using NLLLoss() function defined above\n",
    "\n",
    "\n",
    "Back Propogation:\n",
    "* back propogation is done by simply loss.backward() function\n",
    "\n",
    "Working on test data<br>\n",
    "predicting Y with X test data<br>\n",
    "Finding test loss same as training loss, but we will not back propogate this loss<br>\n",
    "\n",
    "Finding accuracy \n",
    "* we used .eq() function which computes element-wise equality\n",
    "* returns 1 if element is equal else 0 (Hence its summation will give us total correct predictions)\n",
    "\n",
    "We append all data in the form of list per epoch so that it will be easier for us to plot graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 1.2374279499053955\n",
      "Epoch 100 loss 0.09370845556259155\n",
      "Epoch 200 loss 0.33703213930130005\n",
      "Epoch 300 loss 0.04161982983350754\n",
      "Epoch 400 loss 0.03735429793596268\n",
      "Epoch 500 loss 0.03491339087486267\n",
      "Epoch 600 loss 0.03336271271109581\n",
      "Epoch 700 loss 0.032282955944538116\n",
      "Epoch 800 loss 0.03135195001959801\n",
      "Epoch 900 loss 0.030197054147720337\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    Ypred = model(Xtrain_)\n",
    "\n",
    "    loss = loss_fn(Ypred , Ytrain_)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print ('Epoch', epoch, 'loss', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "* saves and loads the entire model, all the intermediate variables as well, like intermediate outputs for back propagation use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0773, -0.1097,  0.2621,  ..., -0.2325,  0.0918,  0.1510],\n",
       "         [ 0.0688, -0.0662,  0.2192,  ..., -0.2004, -0.1044,  0.1772],\n",
       "         [ 0.1836,  0.2435,  0.1673,  ...,  0.0829, -0.1532, -0.2352],\n",
       "         ...,\n",
       "         [-0.0864,  0.0541,  0.0614,  ...,  0.0902,  0.1654, -0.1038],\n",
       "         [ 0.0527, -0.2339,  0.1291,  ..., -0.2668, -0.2348, -0.1155],\n",
       "         [-0.1834,  0.0694,  0.2361,  ..., -0.0612, -0.2456, -0.0447]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.2292,  0.2082,  0.1403, -0.0262,  0.1446, -0.2530, -0.1569,  0.1160,\n",
       "          0.0215, -0.1281, -0.0627, -0.2238,  0.0942, -0.1678,  0.0757,  0.0058,\n",
       "         -0.2191, -0.1466,  0.0339, -0.0829,  0.2397, -0.1417, -0.1658,  0.1268,\n",
       "          0.1997,  0.1813, -0.2599,  0.2112, -0.1270,  0.2615, -0.1047, -0.1651,\n",
       "          0.4089,  0.1107,  0.9022, -0.2060,  0.2283,  0.0341, -0.0320, -0.2728,\n",
       "          0.0720, -0.1814,  0.0508, -0.2135,  0.0707, -0.0557, -0.1073, -0.1982,\n",
       "          0.0521, -0.2331, -0.0792,  0.1455,  0.1206, -0.2706, -0.1839,  0.3736,\n",
       "         -0.1533,  0.0546, -0.1217,  0.1463, -0.1825,  0.0799,  0.2682, -0.1768,\n",
       "         -0.2549,  0.1428, -0.7361,  0.0765, -0.2931,  0.2605,  0.1931,  0.0395,\n",
       "          0.0042, -0.0239, -0.2297,  0.2546, -0.0856, -0.0529, -0.0233,  0.1486,\n",
       "          0.0736, -0.2683,  0.2354,  0.0430, -0.0056,  0.0942, -0.5746, -0.8963,\n",
       "          0.2250, -0.0335,  0.0168, -0.2877,  0.2427, -0.2608, -0.2329, -0.0451,\n",
       "         -0.0622, -0.0059,  0.1065,  0.1035], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.0551, -0.0309,  0.0657,  ..., -0.0024, -0.0839, -0.0573],\n",
       "         [ 0.0139,  0.0488, -0.0018,  ...,  0.0218, -0.0594, -0.0186],\n",
       "         [-0.0399, -0.0166,  0.0334,  ..., -0.0809, -0.0487,  0.0175],\n",
       "         ...,\n",
       "         [-0.0746, -0.1234, -0.0353,  ...,  0.0986, -0.0877, -0.0923],\n",
       "         [-0.0167,  0.0754, -0.0780,  ...,  0.0087,  0.0635,  0.0992],\n",
       "         [-0.0728,  0.0208,  0.0305,  ...,  0.0587, -0.0266,  0.0108]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0729, -0.0777,  0.0511,  0.1048,  0.0492, -0.0317,  0.0330, -0.1372,\n",
       "          0.0450, -0.0038, -0.0490, -0.1118,  0.0450,  0.0937, -0.1083,  0.0337,\n",
       "          0.0163, -0.0318,  0.0919,  0.0029,  0.0072, -0.0739,  0.0289,  0.0367,\n",
       "         -0.0091, -0.0890, -0.0802,  0.0316, -0.0174,  0.0540,  0.0888, -0.0216,\n",
       "          0.0226, -0.0933, -0.1428, -0.0435,  0.0270, -0.0857,  0.0760, -0.0063,\n",
       "          0.0829,  0.0575, -0.1012, -0.1206,  0.0647, -0.1299, -0.0820, -0.0576,\n",
       "          0.0784, -0.0944,  0.0627, -0.1093,  0.0667,  0.0095,  0.0876,  0.1142,\n",
       "          0.0228,  0.0864,  0.0484,  0.0399, -0.0300,  0.0676,  0.0220,  0.0936,\n",
       "          0.0659,  0.0221, -0.0740, -0.1092, -0.0021, -0.0368, -0.0136,  0.1218,\n",
       "          0.0024,  0.0441,  0.0213, -0.0180, -0.0621, -0.0149, -0.0056,  0.0080,\n",
       "         -0.0402,  0.0404,  0.0149,  0.0263,  0.0286, -0.0538,  0.0101,  0.0398,\n",
       "          0.0244,  0.0246, -0.0223, -0.0682,  0.0594,  0.0552,  0.0403,  0.0893,\n",
       "         -0.0166, -0.0285, -0.0889,  0.0151], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.3913,  0.2673, -0.3713,  0.2966,  0.3367,  0.5317, -0.2938, -0.0870,\n",
       "           0.4347, -0.1356, -0.2410,  0.3877,  0.4390, -0.3397,  0.4543,  0.3252,\n",
       "          -0.1208,  0.2968,  0.2829,  0.2467, -0.4125, -0.2300,  0.4121,  0.1678,\n",
       "          -0.3188,  0.1403, -0.3853, -0.3111, -0.3635, -0.1806,  0.1231,  0.0222,\n",
       "           0.3764, -0.2063,  0.1136,  0.4184,  0.2285, -0.0676, -0.2910,  0.3383,\n",
       "           0.2547, -0.2262, -0.2083, -0.0197, -0.5649,  0.0726, -0.1963,  0.2631,\n",
       "          -0.5026,  0.4932, -0.1238, -0.1636, -0.2380, -0.1714,  0.3597,  0.3180,\n",
       "          -0.3360, -0.3330, -0.0389, -0.3577,  0.4065,  0.1856, -0.3776, -0.4419,\n",
       "           0.3665,  0.1671, -0.2904,  0.3589,  0.3671, -0.3226,  0.2407,  0.0276,\n",
       "          -0.2257, -0.1648, -0.2938, -0.3599, -0.4674,  0.1725, -0.7727, -0.4195,\n",
       "           0.1747, -0.2784,  0.4725,  0.2240, -0.0353, -0.2253, -0.3967, -0.0018,\n",
       "           0.3723,  0.1840, -0.0264, -0.5748, -0.2817, -0.2815,  0.3558,  0.2365,\n",
       "           0.4997, -0.1875, -0.2342, -0.3133],\n",
       "         [ 0.3290, -0.5398,  0.0318, -0.2847,  0.2533, -0.1108,  0.1709,  0.3338,\n",
       "          -0.3550, -0.5379,  0.3041,  0.0323, -0.3482, -0.4349, -0.1784, -0.4155,\n",
       "           0.4599, -0.4562, -0.6360, -0.5914,  0.0871,  0.1443, -0.3284,  0.1912,\n",
       "          -0.4557,  0.3514,  0.1107,  0.3691,  0.3897,  0.4441, -0.4415,  0.0235,\n",
       "           0.0468,  0.3115,  0.3678, -0.3572, -0.5394,  0.3050,  0.2428,  0.1139,\n",
       "          -0.5547,  0.3236,  0.4454,  0.3911,  0.0877,  0.4203,  0.3809, -0.4409,\n",
       "           0.1905,  0.1206,  0.4332,  0.2152, -0.3726, -0.2708, -0.2875, -0.5426,\n",
       "           0.2230,  0.2615,  0.3833,  0.1471, -0.3387, -0.4573,  0.1312, -0.3703,\n",
       "          -0.2324,  0.1358, -0.3649, -0.3035,  0.0684, -0.0565,  0.1521, -0.3404,\n",
       "           0.3457, -0.4043,  0.4313,  0.2840, -0.0385,  0.2119,  0.1939, -0.4395,\n",
       "           0.1407,  0.2331, -0.3171, -0.4845,  0.3727,  0.2652,  0.1791,  0.1842,\n",
       "          -0.4174,  0.4841, -0.4126,  0.1921,  0.4397,  0.2609, -0.3535, -0.4344,\n",
       "          -0.0666,  0.3239,  0.4128,  0.2873],\n",
       "         [ 0.0174,  0.2304,  0.3000,  0.1358, -0.5429, -0.6689,  0.0885, -0.3140,\n",
       "          -0.3430,  0.7661, -0.2311, -0.5866, -0.3376,  0.7265, -0.5837, -0.0255,\n",
       "          -0.2274,  0.0351,  0.3303,  0.1568,  0.4853,  0.3000, -0.4404, -0.4249,\n",
       "           0.6617, -0.6606,  0.2344, -0.0795,  0.1436, -0.3692,  0.3530, -0.0126,\n",
       "          -0.6785, -0.2707, -0.6073, -0.2037,  0.3997, -0.2689,  0.1310, -0.7263,\n",
       "           0.2859, -0.1322, -0.3124, -0.5065,  0.6153, -0.4485, -0.1797,  0.0574,\n",
       "           0.2622, -0.6439, -0.4200,  0.0679,  0.7586,  0.3346, -0.0805,  0.0410,\n",
       "           0.1922,  0.2439, -0.4796,  0.2655, -0.2004,  0.1263,  0.1146,  0.9247,\n",
       "          -0.1678, -0.6919,  0.7478, -0.3683, -0.7903,  0.4524, -0.4655,  0.4970,\n",
       "          -0.1338,  0.6154,  0.0429,  0.1492,  0.7018, -0.6155,  0.6045,  0.9124,\n",
       "          -0.8859, -0.0204, -0.1025,  0.2335, -0.3966, -0.0179,  0.3120, -0.5119,\n",
       "          -0.1573, -0.7155,  0.5837,  0.5124, -0.1246,  0.1995, -0.0539,  0.0922,\n",
       "          -0.6287, -0.0745, -0.3427,  0.1135]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0387, -0.1392, -0.0423], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'models/classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat models/classifier.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model\n",
    "* We saved the entire model and not the state dict. Loading requires the class definition to be in the same script as well.\n",
    "* **Compute the accuracy, precision and recall from the loaded model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.load('models/classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_out = new_model(Xtest_)\n",
    "_, predict_y = torch.max(predict_out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy 0.9305555555555556\n",
      "micro precision 0.9305555555555556\n",
      "micro recall 0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print ('prediction accuracy', accuracy_score(Ytest_.data, predict_y.data))\n",
    "print ('micro precision', precision_score(Ytest_.data, predict_y.data, average='micro'))\n",
    "print ('micro recall', recall_score(Ytest_.data, predict_y.data, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
