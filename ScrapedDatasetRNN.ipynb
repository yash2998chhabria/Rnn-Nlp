{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScrapedDatasetRNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNy8cVV3W6ruvdW+C1vZ8dM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yash2998chhabria/Rnn-Nlp/blob/master/ScrapedDatasetRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfJwFvTrLUOB",
        "outputId": "66ad6f01-123b-4bbf-f440-11ed69f046b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwxeRu5DMYte"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEbACTB4Lde9"
      },
      "source": [
        "Combined_df = pd.read_csv(\"/content/drive/MyDrive/depressionrnn/scrapedtotaldataset.csv\") "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "DZfQPkOlMVbJ",
        "outputId": "39631556-0f48-4ac6-d393-abc1df638b90"
      },
      "source": [
        "Combined_df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It started with feeling irritated over small i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>At 16 years old I sat in my first therapy sess...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Depression is debilitating.,Some people unders...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Depression can be a face of someone who is smi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For a long while, I've been having issues with...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365</th>\n",
              "      <td>&amp;nbsp;\\r\\n\\r\\n*[Previous chapter](https://www....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>\\[[first](https://www.reddit.com/r/HFY/comment...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1367</th>\n",
              "      <td>\\[[first](https://www.reddit.com/r/HFY/comment...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1368</th>\n",
              "      <td>\\[[first](https://www.reddit.com/r/HFY/comment...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1369</th>\n",
              "      <td>\\[[first](https://www.reddit.com/r/HFY/comment...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1370 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  story  condition\n",
              "0     It started with feeling irritated over small i...          1\n",
              "1     At 16 years old I sat in my first therapy sess...          1\n",
              "2     Depression is debilitating.,Some people unders...          1\n",
              "3     Depression can be a face of someone who is smi...          1\n",
              "4     For a long while, I've been having issues with...          1\n",
              "...                                                 ...        ...\n",
              "1365  &nbsp;\\r\\n\\r\\n*[Previous chapter](https://www....          0\n",
              "1366  \\[[first](https://www.reddit.com/r/HFY/comment...          0\n",
              "1367  \\[[first](https://www.reddit.com/r/HFY/comment...          0\n",
              "1368  \\[[first](https://www.reddit.com/r/HFY/comment...          0\n",
              "1369  \\[[first](https://www.reddit.com/r/HFY/comment...          0\n",
              "\n",
              "[1370 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeUmRE3qMkXR"
      },
      "source": [
        "import spacy\n",
        "import torch\n",
        "import torchtext\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import re"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7WyM_5Mof8"
      },
      "source": [
        "tweets = Combined_df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BEEyPbZtMpyr",
        "outputId": "b856ea0c-c4c1-498d-95c2-1cb5cd70b038"
      },
      "source": [
        "tweets = tweets.rename(index = str, columns = {'story': 'SentimentText', 'condition': 'Sentiment'})\n",
        "\n",
        "tweets.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It started with feeling irritated over small i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>At 16 years old I sat in my first therapy sess...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Depression is debilitating.,Some people unders...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Depression can be a face of someone who is smi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For a long while, I've been having issues with...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       SentimentText  Sentiment\n",
              "0  It started with feeling irritated over small i...          1\n",
              "1  At 16 years old I sat in my first therapy sess...          1\n",
              "2  Depression is debilitating.,Some people unders...          1\n",
              "3  Depression can be a face of someone who is smi...          1\n",
              "4  For a long while, I've been having issues with...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3eI1i8pMrIO"
      },
      "source": [
        "tweets=tweets.dropna()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbf9hMgnMxYC",
        "outputId": "bbd8c268-5354-4817-e71a-861cf85c5086"
      },
      "source": [
        "tweets.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1368, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-pBTDrYMyjk",
        "outputId": "90fe70eb-e7b4-4adc-eeae-da6f273878ed"
      },
      "source": [
        "tweets['Sentiment'].unique()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrVj3bA2Mz6k",
        "outputId": "36c5bf60-eef5-420e-e5d3-ad475905d711"
      },
      "source": [
        "tweets.Sentiment.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    699\n",
              "0    669\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "wQoze4SAM1Yb",
        "outputId": "99dde901-6028-40b3-c5cc-15deb8b2a43a"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "\n",
        "ax = sns.barplot(x=tweets.Sentiment.unique(), y=tweets.Sentiment.value_counts())\n",
        "\n",
        "ax.set(xlabel='Labels')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 0, 'Labels')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo84wJXLM3w5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(tweets, test_size=0.2, random_state=42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzmmRKxNM6cE",
        "outputId": "e2d16f3e-29f5-46c1-9c67-8a248e3c9860"
      },
      "source": [
        "train.reset_index(drop=True), test.reset_index(drop=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                          SentimentText  Sentiment\n",
              " 0     I have struggled with , , and , for the past 2...          1\n",
              " 1       When I was 18 and still in high school, I we...          0\n",
              " 2     There are seminal moments, defining moments in...          1\n",
              " 3     Ok, so today I went to a zoom meeting about cl...          0\n",
              " 4     Everything has limits, except for humans.  Or ...          0\n",
              " ...                                                 ...        ...\n",
              " 1089  Just wanted to post an update for the fraud Pl...          0\n",
              " 1090  https://www.reddit.com/r/legaladvice/comments/...          0\n",
              " 1091  &nbsp;\\r\\n\\r\\n*[Previous chapter](https://www....          0\n",
              " 1092  As a kid we would go to upstate New York on va...          0\n",
              " 1093  California here, getting that out of the way. ...          0\n",
              " \n",
              " [1094 rows x 2 columns],\n",
              "                                          SentimentText  Sentiment\n",
              " 0    OCD... Oh yeah... OCD is about neatness and ti...          1\n",
              " 1    This afternoon I found out girls have been kic...          0\n",
              " 2    To say that my life has been a upward challeng...          1\n",
              " 3    These are the words which you worry you’ll com...          1\n",
              " 4    It’s so important to surround yourself with , ...          1\n",
              " ..                                                 ...        ...\n",
              " 269  My dad passed away last week while at work. He...          0\n",
              " 270  I f(18) have only told 4 people about the even...          0\n",
              " 271  My mum and dad were diagnosed with , and ,, re...          1\n",
              " 272  Nick died tragically early in January 2015. He...          1\n",
              " 273  So I'm at a party and I'm doing okay. I've man...          1\n",
              " \n",
              " [274 rows x 2 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j54Z8zkQM7wl",
        "outputId": "7110f363-5d27-4c95-801c-0e90051c1947"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1094, 2), (274, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rovvY6dUM9t6"
      },
      "source": [
        "train.to_csv('/content/drive/MyDrive/depressionrnn/train_tweets.csv', index=False)\n",
        "test.to_csv('/content/drive/MyDrive/depressionrnn/test_tweets.csv', index=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qsTsJpqNXgu"
      },
      "source": [
        "def tweet_clean(text):\n",
        "    \n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) \n",
        "    text = re.sub(r'https?:/\\/\\S+', ' ', text) \n",
        "    \n",
        "    return text.strip()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwZtVSU6NZM5"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
        "\n",
        "def tokenizer(s): \n",
        "    return [w.text.lower() for w in nlp(tweet_clean(s))]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CApt5MRcNazA"
      },
      "source": [
        "TEXT = torchtext.data.Field(tokenize = tokenizer)\n",
        "\n",
        "LABEL = torchtext.data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp39GHAVNcIO"
      },
      "source": [
        "datafields = [('SentimentText', TEXT),('Sentiment', LABEL)]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uubrkjDNdP3"
      },
      "source": [
        "trn, tst = torchtext.data.TabularDataset.splits(path = '/content/drive/MyDrive/depressionrnn/', \n",
        "                                                train = 'train_tweets.csv',\n",
        "                                                test = 'test_tweets.csv',    \n",
        "                                                format = 'csv',\n",
        "                                                skip_header = True,\n",
        "                                                fields = datafields)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBYfJ2DmNeiM",
        "outputId": "5e84cac3-ea72-4cc5-86d7-723c40cc9e88"
      },
      "source": [
        "print(f'Number of training examples: {len(trn)}')\n",
        "print(f'Number of testing examples: {len(tst)}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 1094\n",
            "Number of testing examples: 274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40SoCqzeNh33",
        "outputId": "f48e3a26-936c-4258-a1d6-72f07ab1c120"
      },
      "source": [
        "vars(trn.examples[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': '1',\n",
              " 'SentimentText': ['i',\n",
              "  'have',\n",
              "  'struggled',\n",
              "  'with',\n",
              "  'and',\n",
              "  'for',\n",
              "  'the',\n",
              "  'past',\n",
              "  '2',\n",
              "  'years',\n",
              "  'during',\n",
              "  'this',\n",
              "  'time',\n",
              "  'i',\n",
              "  'also',\n",
              "  'had',\n",
              "  'a',\n",
              "  'baby',\n",
              "  'and',\n",
              "  'i',\n",
              "  'am',\n",
              "  'also',\n",
              "  'a',\n",
              "  'busy',\n",
              "  'mum',\n",
              "  'to',\n",
              "  'my',\n",
              "  '15',\n",
              "  'year',\n",
              "  'old',\n",
              "  'daughter',\n",
              "  'i',\n",
              "  've',\n",
              "  'also',\n",
              "  'had',\n",
              "  'lots',\n",
              "  'of',\n",
              "  'support',\n",
              "  'from',\n",
              "  'my',\n",
              "  'husband',\n",
              "  'a',\n",
              "  'team',\n",
              "  'of',\n",
              "  'healthcare',\n",
              "  'professionals',\n",
              "  'family',\n",
              "  'and',\n",
              "  'friends',\n",
              "  'being',\n",
              "  'involved',\n",
              "  'with',\n",
              "  'the',\n",
              "  'campaign',\n",
              "  'and',\n",
              "  'attending',\n",
              "  'a',\n",
              "  'recovery',\n",
              "  'college',\n",
              "  'has',\n",
              "  'really',\n",
              "  'motivated',\n",
              "  'me',\n",
              "  'in',\n",
              "  'fact',\n",
              "  'i',\n",
              "  'am',\n",
              "  'recovering',\n",
              "  'well',\n",
              "  'that',\n",
              "  'i',\n",
              "  'felt',\n",
              "  'it',\n",
              "  'was',\n",
              "  'time',\n",
              "  'to',\n",
              "  'give',\n",
              "  'myself',\n",
              "  'a',\n",
              "  'daily',\n",
              "  'challenge',\n",
              "  'every',\n",
              "  'day',\n",
              "  'i',\n",
              "  'try',\n",
              "  'to',\n",
              "  'talk',\n",
              "  'briefly',\n",
              "  'to',\n",
              "  'a',\n",
              "  'random',\n",
              "  'stranger',\n",
              "  'about',\n",
              "  'the',\n",
              "  'difficulties',\n",
              "  'i',\n",
              "  'have',\n",
              "  'faced',\n",
              "  'and',\n",
              "  'to',\n",
              "  'talk',\n",
              "  'about',\n",
              "  'mental',\n",
              "  'health',\n",
              "  'today',\n",
              "  'it',\n",
              "  'was',\n",
              "  'a',\n",
              "  'lady',\n",
              "  'in',\n",
              "  'the',\n",
              "  'supermarket',\n",
              "  'but',\n",
              "  'last',\n",
              "  'friday',\n",
              "  'in',\n",
              "  'was',\n",
              "  'a',\n",
              "  'children',\n",
              "  's',\n",
              "  'entertainer',\n",
              "  'i',\n",
              "  'imagine',\n",
              "  'that',\n",
              "  'if',\n",
              "  'i',\n",
              "  'had',\n",
              "  'a',\n",
              "  'badly',\n",
              "  'broken',\n",
              "  'arm',\n",
              "  'with',\n",
              "  'pins',\n",
              "  'in',\n",
              "  'it',\n",
              "  'the',\n",
              "  'random',\n",
              "  'stranger',\n",
              "  'might',\n",
              "  'ask',\n",
              "  'me',\n",
              "  'how',\n",
              "  'i',\n",
              "  'did',\n",
              "  'it',\n",
              "  'or',\n",
              "  'if',\n",
              "  'it',\n",
              "  's',\n",
              "  'getting',\n",
              "  'better',\n",
              "  'it',\n",
              "  's',\n",
              "  'not',\n",
              "  'very',\n",
              "  'easy',\n",
              "  'starting',\n",
              "  'the',\n",
              "  'conversation',\n",
              "  'and',\n",
              "  'sometimes',\n",
              "  'i',\n",
              "  'do',\n",
              "  'get',\n",
              "  'the',\n",
              "  'odd',\n",
              "  'really',\n",
              "  'or',\n",
              "  'oh',\n",
              "  'dear',\n",
              "  'but',\n",
              "  'generally',\n",
              "  'i',\n",
              "  'find',\n",
              "  'people',\n",
              "  'are',\n",
              "  'happy',\n",
              "  'to',\n",
              "  'have',\n",
              "  'a',\n",
              "  'short',\n",
              "  'conversation',\n",
              "  'so',\n",
              "  'what',\n",
              "  'do',\n",
              "  'we',\n",
              "  'all',\n",
              "  'get',\n",
              "  'out',\n",
              "  'of',\n",
              "  'it',\n",
              "  'well',\n",
              "  'it',\n",
              "  's',\n",
              "  'my',\n",
              "  'way',\n",
              "  'of',\n",
              "  'getting',\n",
              "  'people',\n",
              "  'to',\n",
              "  'talk',\n",
              "  'about',\n",
              "  'mental',\n",
              "  'health',\n",
              "  'which',\n",
              "  'i',\n",
              "  'hope',\n",
              "  'will',\n",
              "  'make',\n",
              "  'a',\n",
              "  'tiny',\n",
              "  'difference',\n",
              "  'to',\n",
              "  'combat',\n",
              "  'the',\n",
              "  'stigma',\n",
              "  'around',\n",
              "  'the',\n",
              "  'subject',\n",
              "  'and',\n",
              "  'for',\n",
              "  'them',\n",
              "  'to',\n",
              "  'be',\n",
              "  'a',\n",
              "  'little',\n",
              "  'more',\n",
              "  'enlightened',\n",
              "  'and',\n",
              "  'perhaps',\n",
              "  'more',\n",
              "  'comfortable',\n",
              "  'to',\n",
              "  'talk',\n",
              "  'to',\n",
              "  'loved',\n",
              "  'ones',\n",
              "  'colleagues',\n",
              "  'or',\n",
              "  'friends',\n",
              "  'about',\n",
              "  'mental',\n",
              "  'health',\n",
              "  'talking',\n",
              "  'to',\n",
              "  'people',\n",
              "  'makes',\n",
              "  'me',\n",
              "  'feel',\n",
              "  'empowered',\n",
              "  'and',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'ways',\n",
              "  'i',\n",
              "  'am',\n",
              "  'trying',\n",
              "  'to',\n",
              "  'thank',\n",
              "  'those',\n",
              "  'of',\n",
              "  'who',\n",
              "  'helped',\n",
              "  'and',\n",
              "  'supported',\n",
              "  'me',\n",
              "  'i',\n",
              "  'am',\n",
              "  'gaining',\n",
              "  'confidence',\n",
              "  'and',\n",
              "  'no',\n",
              "  'longer',\n",
              "  'feel',\n",
              "  'ashamed',\n",
              "  'about',\n",
              "  'my',\n",
              "  'mental',\n",
              "  'health',\n",
              "  'so',\n",
              "  'last',\n",
              "  'friday',\n",
              "  's',\n",
              "  'conversation',\n",
              "  'went',\n",
              "  'something',\n",
              "  'like',\n",
              "  'this',\n",
              "  'magician',\n",
              "  'man',\n",
              "  'asks',\n",
              "  'have',\n",
              "  'you',\n",
              "  'ever',\n",
              "  'been',\n",
              "  'to',\n",
              "  'winchester',\n",
              "  'before',\n",
              "  'i',\n",
              "  'reply',\n",
              "  'actually',\n",
              "  'i',\n",
              "  'lived',\n",
              "  'here',\n",
              "  'for',\n",
              "  'three',\n",
              "  'months',\n",
              "  'last',\n",
              "  'year',\n",
              "  'only',\n",
              "  'three',\n",
              "  'months',\n",
              "  'he',\n",
              "  'replies',\n",
              "  'that',\n",
              "  'was',\n",
              "  'a',\n",
              "  'short',\n",
              "  'stay',\n",
              "  'well',\n",
              "  'too',\n",
              "  'be',\n",
              "  'honest',\n",
              "  'i',\n",
              "  'was',\n",
              "  'in',\n",
              "  'a',\n",
              "  'specialist',\n",
              "  'psychiatric',\n",
              "  'unit',\n",
              "  'just',\n",
              "  'up',\n",
              "  'the',\n",
              "  'road',\n",
              "  'so',\n",
              "  'that',\n",
              "  's',\n",
              "  'why',\n",
              "  'i',\n",
              "  'was',\n",
              "  'here',\n",
              "  'magician',\n",
              "  'man',\n",
              "  'says',\n",
              "  'wow',\n",
              "  'i',\n",
              "  'm',\n",
              "  'sorry',\n",
              "  'to',\n",
              "  'hear',\n",
              "  'that',\n",
              "  'are',\n",
              "  'you',\n",
              "  'better',\n",
              "  'now',\n",
              "  'and',\n",
              "  'so',\n",
              "  'we',\n",
              "  'chat',\n",
              "  'for',\n",
              "  'about',\n",
              "  '5',\n",
              "  'minutes',\n",
              "  'he',\n",
              "  'tells',\n",
              "  'me',\n",
              "  'about',\n",
              "  'a',\n",
              "  'family',\n",
              "  'member',\n",
              "  'who',\n",
              "  'had',\n",
              "  'been',\n",
              "  'unwell',\n",
              "  'and',\n",
              "  'i',\n",
              "  'tell',\n",
              "  'him',\n",
              "  'about',\n",
              "  'my',\n",
              "  'experiences',\n",
              "  'and',\n",
              "  'how',\n",
              "  'i',\n",
              "  'am',\n",
              "  'recovering',\n",
              "  'job',\n",
              "  'done',\n",
              "  'for',\n",
              "  'today',\n",
              "  'comment',\n",
              "  'below',\n",
              "  'or',\n",
              "  'and',\n",
              "  'find',\n",
              "  'out']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCafx3-8NyOV",
        "outputId": "3ee83c80-197a-4bd3-ff15-138cb2ed2787"
      },
      "source": [
        "vars(tst.examples[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': '1',\n",
              " 'SentimentText': ['ocd',\n",
              "  'oh',\n",
              "  'yeah',\n",
              "  'ocd',\n",
              "  'is',\n",
              "  'about',\n",
              "  'neatness',\n",
              "  'and',\n",
              "  'tidiness',\n",
              "  'isn',\n",
              "  't',\n",
              "  'it',\n",
              "  'it',\n",
              "  's',\n",
              "  'about',\n",
              "  'keeping',\n",
              "  'things',\n",
              "  'in',\n",
              "  'order',\n",
              "  'it',\n",
              "  's',\n",
              "  'washing',\n",
              "  'your',\n",
              "  'hands',\n",
              "  'a',\n",
              "  'lot',\n",
              "  'this',\n",
              "  'was',\n",
              "  'my',\n",
              "  'and',\n",
              "  'i',\n",
              "  'm',\n",
              "  'sure',\n",
              "  'many',\n",
              "  'other',\n",
              "  'people',\n",
              "  's',\n",
              "  'view',\n",
              "  'of',\n",
              "  'ocd',\n",
              "  'in',\n",
              "  'fact',\n",
              "  'i',\n",
              "  'make',\n",
              "  'fun',\n",
              "  'of',\n",
              "  'myself',\n",
              "  'a',\n",
              "  'lot',\n",
              "  'because',\n",
              "  'i',\n",
              "  'am',\n",
              "  'incredibly',\n",
              "  'untidy',\n",
              "  'i',\n",
              "  'wish',\n",
              "  'i',\n",
              "  'had',\n",
              "  'the',\n",
              "  'tidiness',\n",
              "  'part',\n",
              "  'of',\n",
              "  'ocd',\n",
              "  'i',\n",
              "  'claim',\n",
              "  'but',\n",
              "  'i',\n",
              "  'know',\n",
              "  'that',\n",
              "  'really',\n",
              "  'i',\n",
              "  'wish',\n",
              "  'i',\n",
              "  'didn',\n",
              "  't',\n",
              "  'experience',\n",
              "  'this',\n",
              "  'condition',\n",
              "  'at',\n",
              "  'all',\n",
              "  'people',\n",
              "  'laugh',\n",
              "  'about',\n",
              "  'the',\n",
              "  'compulsions',\n",
              "  'that',\n",
              "  'can',\n",
              "  'come',\n",
              "  'with',\n",
              "  'ocd',\n",
              "  'i',\n",
              "  'know',\n",
              "  'i',\n",
              "  'have',\n",
              "  'done',\n",
              "  'it',\n",
              "  'myself',\n",
              "  'with',\n",
              "  'a',\n",
              "  'laugh',\n",
              "  'they',\n",
              "  'say',\n",
              "  'oh',\n",
              "  'i',\n",
              "  've',\n",
              "  'got',\n",
              "  'that',\n",
              "  'i',\n",
              "  'check',\n",
              "  'the',\n",
              "  'door',\n",
              "  'all',\n",
              "  'the',\n",
              "  'time',\n",
              "  'or',\n",
              "  'i',\n",
              "  'know',\n",
              "  'what',\n",
              "  'you',\n",
              "  'mean',\n",
              "  'i',\n",
              "  'm',\n",
              "  'a',\n",
              "  'neat',\n",
              "  'freak',\n",
              "  'this',\n",
              "  'makes',\n",
              "  'any',\n",
              "  'explanation',\n",
              "  'harder',\n",
              "  'in',\n",
              "  'some',\n",
              "  'ways',\n",
              "  'because',\n",
              "  'they',\n",
              "  'may',\n",
              "  'just',\n",
              "  'do',\n",
              "  'these',\n",
              "  'things',\n",
              "  'with',\n",
              "  'no',\n",
              "  'compulsion',\n",
              "  'involved',\n",
              "  'i',\n",
              "  'have',\n",
              "  'not',\n",
              "  'told',\n",
              "  'many',\n",
              "  'people',\n",
              "  'about',\n",
              "  'the',\n",
              "  'ocd',\n",
              "  'thing',\n",
              "  'lots',\n",
              "  'of',\n",
              "  'people',\n",
              "  'know',\n",
              "  'that',\n",
              "  'i',\n",
              "  'have',\n",
              "  'and',\n",
              "  'but',\n",
              "  'when',\n",
              "  'people',\n",
              "  'think',\n",
              "  'that',\n",
              "  'ocd',\n",
              "  'is',\n",
              "  'all',\n",
              "  'about',\n",
              "  'tidiness',\n",
              "  'because',\n",
              "  'that',\n",
              "  's',\n",
              "  'what',\n",
              "  'tv',\n",
              "  'shows',\n",
              "  'them',\n",
              "  'then',\n",
              "  'how',\n",
              "  'can',\n",
              "  'i',\n",
              "  'explain',\n",
              "  'my',\n",
              "  'ocd',\n",
              "  'i',\n",
              "  'worry',\n",
              "  'that',\n",
              "  'people',\n",
              "  'will',\n",
              "  'not',\n",
              "  'believe',\n",
              "  'me',\n",
              "  'because',\n",
              "  'if',\n",
              "  'i',\n",
              "  'was',\n",
              "  'washing',\n",
              "  'my',\n",
              "  'hands',\n",
              "  'or',\n",
              "  'keeping',\n",
              "  'my',\n",
              "  'stuff',\n",
              "  'majorly',\n",
              "  'tidy',\n",
              "  'then',\n",
              "  'you',\n",
              "  'would',\n",
              "  'be',\n",
              "  'able',\n",
              "  'to',\n",
              "  'see',\n",
              "  'it',\n",
              "  'my',\n",
              "  'ocd',\n",
              "  'is',\n",
              "  'hidden',\n",
              "  'in',\n",
              "  'my',\n",
              "  'head',\n",
              "  'and',\n",
              "  'leaves',\n",
              "  'me',\n",
              "  'with',\n",
              "  'this',\n",
              "  'crippling',\n",
              "  'anxiety',\n",
              "  'so',\n",
              "  'that',\n",
              "  'i',\n",
              "  'can',\n",
              "  't',\n",
              "  'function',\n",
              "  'properly',\n",
              "  'the',\n",
              "  'people',\n",
              "  'that',\n",
              "  'i',\n",
              "  'have',\n",
              "  'told',\n",
              "  'are',\n",
              "  'the',\n",
              "  'people',\n",
              "  'that',\n",
              "  'i',\n",
              "  'knew',\n",
              "  'would',\n",
              "  'make',\n",
              "  'the',\n",
              "  'big',\n",
              "  'effort',\n",
              "  'to',\n",
              "  'understand',\n",
              "  'anyway',\n",
              "  'the',\n",
              "  'people',\n",
              "  'that',\n",
              "  'have',\n",
              "  'been',\n",
              "  'there',\n",
              "  'for',\n",
              "  'me',\n",
              "  'when',\n",
              "  'i',\n",
              "  'have',\n",
              "  'been',\n",
              "  'off',\n",
              "  'work',\n",
              "  'with',\n",
              "  'anxiety',\n",
              "  'and',\n",
              "  'the',\n",
              "  'people',\n",
              "  'who',\n",
              "  'ask',\n",
              "  'how',\n",
              "  'i',\n",
              "  'am',\n",
              "  'and',\n",
              "  'care',\n",
              "  'about',\n",
              "  'the',\n",
              "  'answer',\n",
              "  'the',\n",
              "  'fact',\n",
              "  'that',\n",
              "  'it',\n",
              "  'requires',\n",
              "  'a',\n",
              "  'huge',\n",
              "  'explanation',\n",
              "  'puts',\n",
              "  'me',\n",
              "  'off',\n",
              "  'i',\n",
              "  'have',\n",
              "  'to',\n",
              "  'explain',\n",
              "  'the',\n",
              "  'condition',\n",
              "  'first',\n",
              "  'that',\n",
              "  'it',\n",
              "  'is',\n",
              "  'about',\n",
              "  'obsessing',\n",
              "  'and',\n",
              "  'compulsions',\n",
              "  'not',\n",
              "  'that',\n",
              "  'it',\n",
              "  'is',\n",
              "  'about',\n",
              "  'tidiness',\n",
              "  'then',\n",
              "  'move',\n",
              "  'on',\n",
              "  'to',\n",
              "  'how',\n",
              "  'it',\n",
              "  'is',\n",
              "  'for',\n",
              "  'me',\n",
              "  'these',\n",
              "  'people',\n",
              "  'have',\n",
              "  'been',\n",
              "  'ace',\n",
              "  'but',\n",
              "  'i',\n",
              "  'wish',\n",
              "  'i',\n",
              "  'could',\n",
              "  'be',\n",
              "  'more',\n",
              "  'open',\n",
              "  'about',\n",
              "  'it',\n",
              "  'it',\n",
              "  's',\n",
              "  'the',\n",
              "  'fear',\n",
              "  'of',\n",
              "  'people',\n",
              "  'thinking',\n",
              "  'i',\n",
              "  'should',\n",
              "  'just',\n",
              "  'be',\n",
              "  'able',\n",
              "  'to',\n",
              "  'ignore',\n",
              "  'it',\n",
              "  'all',\n",
              "  'and',\n",
              "  'the',\n",
              "  'lack',\n",
              "  'of',\n",
              "  'understanding',\n",
              "  'of',\n",
              "  'what',\n",
              "  'ocd',\n",
              "  'can',\n",
              "  'be',\n",
              "  'that',\n",
              "  'puts',\n",
              "  'me',\n",
              "  'off',\n",
              "  'ideally',\n",
              "  'i',\n",
              "  'would',\n",
              "  'love',\n",
              "  'to',\n",
              "  'be',\n",
              "  'able',\n",
              "  'to',\n",
              "  'explain',\n",
              "  'to',\n",
              "  'more',\n",
              "  'people',\n",
              "  'and',\n",
              "  'all',\n",
              "  'i',\n",
              "  'ask',\n",
              "  'is',\n",
              "  'that',\n",
              "  'they',\n",
              "  'do',\n",
              "  'what',\n",
              "  'the',\n",
              "  'people',\n",
              "  'i',\n",
              "  'have',\n",
              "  'already',\n",
              "  'told',\n",
              "  'did',\n",
              "  'put',\n",
              "  'their',\n",
              "  'previous',\n",
              "  'experience',\n",
              "  'to',\n",
              "  'one',\n",
              "  'side',\n",
              "  'and',\n",
              "  'listen',\n",
              "  'to',\n",
              "  'how',\n",
              "  'it',\n",
              "  'is',\n",
              "  'for',\n",
              "  'me',\n",
              "  'it',\n",
              "  'has',\n",
              "  'taken',\n",
              "  'me',\n",
              "  'until',\n",
              "  'this',\n",
              "  'year',\n",
              "  'to',\n",
              "  'realise',\n",
              "  'that',\n",
              "  'ocd',\n",
              "  'is',\n",
              "  'what',\n",
              "  'i',\n",
              "  'have',\n",
              "  'been',\n",
              "  'living',\n",
              "  'with',\n",
              "  'for',\n",
              "  'the',\n",
              "  'last',\n",
              "  '24',\n",
              "  'years',\n",
              "  'i',\n",
              "  'always',\n",
              "  'thought',\n",
              "  'i',\n",
              "  'was',\n",
              "  'simply',\n",
              "  'rubbish',\n",
              "  'at',\n",
              "  'enjoying',\n",
              "  'things',\n",
              "  'at',\n",
              "  'living',\n",
              "  'in',\n",
              "  'the',\n",
              "  'moment',\n",
              "  'at',\n",
              "  'being',\n",
              "  'sociable',\n",
              "  'with',\n",
              "  'others',\n",
              "  'but',\n",
              "  'what',\n",
              "  'i',\n",
              "  'didn',\n",
              "  't',\n",
              "  'know',\n",
              "  'was',\n",
              "  'that',\n",
              "  'the',\n",
              "  'constant',\n",
              "  'buzz',\n",
              "  'in',\n",
              "  'my',\n",
              "  'head',\n",
              "  'is',\n",
              "  'not',\n",
              "  'normal',\n",
              "  'or',\n",
              "  'at',\n",
              "  'least',\n",
              "  'it',\n",
              "  's',\n",
              "  'not',\n",
              "  'what',\n",
              "  'everyone',\n",
              "  'else',\n",
              "  'experiences',\n",
              "  'this',\n",
              "  'is',\n",
              "  'because',\n",
              "  'i',\n",
              "  'understood',\n",
              "  'ocd',\n",
              "  'in',\n",
              "  'the',\n",
              "  'same',\n",
              "  'way',\n",
              "  'most',\n",
              "  'others',\n",
              "  'did',\n",
              "  'cleaning',\n",
              "  'tidying',\n",
              "  'ordering',\n",
              "  'until',\n",
              "  'i',\n",
              "  'saw',\n",
              "  'one',\n",
              "  'tv',\n",
              "  'programme',\n",
              "  'that',\n",
              "  'showed',\n",
              "  'me',\n",
              "  'different',\n",
              "  'my',\n",
              "  'head',\n",
              "  'is',\n",
              "  'like',\n",
              "  'a',\n",
              "  'horrible',\n",
              "  'person',\n",
              "  'picking',\n",
              "  'up',\n",
              "  'on',\n",
              "  'all',\n",
              "  'the',\n",
              "  'negative',\n",
              "  'feelings',\n",
              "  'i',\n",
              "  'have',\n",
              "  'about',\n",
              "  'myself',\n",
              "  'and',\n",
              "  'obsessively',\n",
              "  'bombarding',\n",
              "  'me',\n",
              "  'with',\n",
              "  'them',\n",
              "  'i',\n",
              "  'am',\n",
              "  'told',\n",
              "  'how',\n",
              "  'rubbish',\n",
              "  'i',\n",
              "  'am',\n",
              "  'how',\n",
              "  'sad',\n",
              "  'how',\n",
              "  'nobody',\n",
              "  'wants',\n",
              "  'anything',\n",
              "  'to',\n",
              "  'do',\n",
              "  'with',\n",
              "  'me',\n",
              "  'and',\n",
              "  'that',\n",
              "  'i',\n",
              "  'will',\n",
              "  'never',\n",
              "  'be',\n",
              "  'normal',\n",
              "  'whatever',\n",
              "  'that',\n",
              "  'means',\n",
              "  'this',\n",
              "  'isn',\n",
              "  't',\n",
              "  'a',\n",
              "  'voice',\n",
              "  'in',\n",
              "  'my',\n",
              "  'head',\n",
              "  'it',\n",
              "  's',\n",
              "  'me',\n",
              "  'telling',\n",
              "  'me',\n",
              "  'which',\n",
              "  'is',\n",
              "  'why',\n",
              "  'it',\n",
              "  'is',\n",
              "  'nearly',\n",
              "  'impossible',\n",
              "  'to',\n",
              "  'fight',\n",
              "  'i',\n",
              "  'compulsively',\n",
              "  'pick',\n",
              "  'away',\n",
              "  'at',\n",
              "  'myself',\n",
              "  'i',\n",
              "  'question',\n",
              "  'everything',\n",
              "  'and',\n",
              "  'if',\n",
              "  'i',\n",
              "  'can',\n",
              "  'see',\n",
              "  'the',\n",
              "  'negative',\n",
              "  'in',\n",
              "  'something',\n",
              "  'then',\n",
              "  'i',\n",
              "  'do',\n",
              "  'this',\n",
              "  'is',\n",
              "  'not',\n",
              "  'low',\n",
              "  'self',\n",
              "  'esteem',\n",
              "  'this',\n",
              "  'is',\n",
              "  'obsessive',\n",
              "  'worrying',\n",
              "  'and',\n",
              "  'compulsive',\n",
              "  'thinking',\n",
              "  'causing',\n",
              "  'pain',\n",
              "  'i',\n",
              "  'can',\n",
              "  't',\n",
              "  'just',\n",
              "  'ignore',\n",
              "  'them',\n",
              "  'all',\n",
              "  'the',\n",
              "  'time',\n",
              "  'i',\n",
              "  'am',\n",
              "  'not',\n",
              "  'giving',\n",
              "  'in',\n",
              "  'to',\n",
              "  'them',\n",
              "  'it',\n",
              "  'hurts',\n",
              "  'and',\n",
              "  'it',\n",
              "  's',\n",
              "  'hard',\n",
              "  'i',\n",
              "  'am',\n",
              "  'writing',\n",
              "  'this',\n",
              "  'in',\n",
              "  'the',\n",
              "  'hope',\n",
              "  'that',\n",
              "  'other',\n",
              "  'people',\n",
              "  'might',\n",
              "  'identify',\n",
              "  'with',\n",
              "  'what',\n",
              "  'i',\n",
              "  'am',\n",
              "  'talking',\n",
              "  'about',\n",
              "  'though',\n",
              "  'i',\n",
              "  'wouldn',\n",
              "  't',\n",
              "  'wish',\n",
              "  'this',\n",
              "  'on',\n",
              "  'anyone',\n",
              "  'and',\n",
              "  'because',\n",
              "  'i',\n",
              "  'think',\n",
              "  'the',\n",
              "  'more',\n",
              "  'people',\n",
              "  'speak',\n",
              "  'out',\n",
              "  'and',\n",
              "  'support',\n",
              "  'each',\n",
              "  'other',\n",
              "  'the',\n",
              "  'easier',\n",
              "  'it',\n",
              "  'may',\n",
              "  'become',\n",
              "  'also',\n",
              "  'i',\n",
              "  'want',\n",
              "  'people',\n",
              "  'to',\n",
              "  'understand',\n",
              "  'that',\n",
              "  'it',\n",
              "  'would',\n",
              "  'be',\n",
              "  'great',\n",
              "  'if',\n",
              "  'people',\n",
              "  'could',\n",
              "  'remember',\n",
              "  'that',\n",
              "  'it',\n",
              "  'stands',\n",
              "  'for',\n",
              "  'obsessive',\n",
              "  'compulsive',\n",
              "  'disorder',\n",
              "  'and',\n",
              "  'not',\n",
              "  'obsessive',\n",
              "  'cleaning',\n",
              "  'disorder']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6POKqpSMN1T8",
        "outputId": "fba8a500-2c58-48c0-95e1-df737a29f679"
      },
      "source": [
        "TEXT.build_vocab(trn, max_size=25000,\n",
        "                 vectors=\"glove.6B.100d\",\n",
        "                 unk_init=torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(trn)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.22MB/s]                          \n",
            " 99%|█████████▉| 397857/400000 [00:20<00:00, 21308.40it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ_Ju966N5Cj",
        "outputId": "02f9bebb-fdc6-4896-c6e3-3aaf7ee46860"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(50))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 40082), ('i', 30574), ('to', 28783), ('and', 25635), ('a', 20110), ('of', 18317), ('that', 13403), ('it', 13368), ('was', 13157), ('my', 12158), ('in', 11162), ('you', 7148), ('me', 7146), ('t', 6976), ('with', 6841), ('for', 6784), ('had', 6434), ('they', 6027), ('as', 5840), ('he', 5790), ('is', 5736), ('on', 5697), ('but', 5459), ('s', 5358), ('have', 5251), ('this', 4878), ('be', 4785), ('we', 4565), ('not', 4408), ('at', 4393), ('from', 3741), ('his', 3708), ('so', 3671), ('she', 3600), ('about', 3484), ('out', 3342), ('were', 3331), ('what', 3268), ('all', 3198), ('her', 3136), ('one', 3081), ('their', 3064), ('when', 3026), ('would', 3008), ('or', 2990), ('up', 2972), ('are', 2957), ('them', 2930), ('can', 2781), ('there', 2756)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6L0qN49N6ov",
        "outputId": "99372f9b-4c1a-472b-a38c-ec5da5163a20"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', 'i', 'to', 'and', 'a', 'of', 'that', 'it']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1Rv3ZTpN7vb",
        "outputId": "c1a32cdd-9e7a-47e5-a57a-81f1488466a6"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f7b0ff39ea0>, {'1': 0, '0': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn3mdhjeN886"
      },
      "source": [
        "train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "                                (trn, tst),\n",
        "                                batch_size = 64,\n",
        "                                sort_key=lambda x: len(x.SentimentText),\n",
        "                                sort_within_batch=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaCgbT8PN-l7"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
        "                 output_dim, n_layers, bidirectional, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
        "                           bidirectional = bidirectional, dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "       \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4iuH_dlOACx"
      },
      "source": [
        "input_dim = len(TEXT.vocab)\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "hidden_dim = 20\n",
        "output_dim = 1\n",
        "\n",
        "n_layers = 2\n",
        "bidirectional = True\n",
        "\n",
        "dropout = 0.5"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ii8AgofOBhX"
      },
      "source": [
        "model = RNN(input_dim, \n",
        "            embedding_dim, \n",
        "            hidden_dim, \n",
        "            output_dim, \n",
        "            n_layers, \n",
        "            bidirectional, \n",
        "            dropout)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY0UvepBOC7a",
        "outputId": "8cd963d1-cd6c-484e-bfd8-2d2fa596bdc6"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ph_qxUOEDt",
        "outputId": "c95e6642-4b4d-4c45-9cfb-e1c75a0113e9"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2264, -0.1698, -0.5443,  ..., -0.8675,  1.5221,  1.0766],\n",
              "        [ 0.0685,  1.7735,  1.5197,  ...,  2.0164, -0.5793,  0.1839],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.0458, -0.2206, -0.4131,  ...,  0.0164, -0.4578,  0.1915],\n",
              "        [-0.6544, -0.7541, -2.9852,  ...,  1.0020,  0.0176,  0.5351],\n",
              "        [-0.4073, -0.4381, -0.7940,  ...,  0.4838, -0.5865,  0.7650]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0fhwnAcOFbs",
        "outputId": "311b074a-88b3-4f12-f391-d7639582dbe4"
      },
      "source": [
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.0458, -0.2206, -0.4131,  ...,  0.0164, -0.4578,  0.1915],\n",
            "        [-0.6544, -0.7541, -2.9852,  ...,  1.0020,  0.0176,  0.5351],\n",
            "        [-0.4073, -0.4381, -0.7940,  ...,  0.4838, -0.5865,  0.7650]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo3vS_0fOG1Z"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr= 0.0005)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR5NdIA6OIH2"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.SentimentText).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.Sentiment)\n",
        "        \n",
        "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "        correct = (rounded_preds == batch.Sentiment).float() \n",
        "        \n",
        "        acc = correct.sum() / len(correct)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os3b1FMPOJup",
        "outputId": "ab95ea67-5703-40d2-d4ca-47b8fe134933"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "     \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 397857/400000 [00:40<00:00, 21308.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.691 | Train Acc: 53.44% |\n",
            "| Epoch: 02 | Train Loss: 0.689 | Train Acc: 52.55% |\n",
            "| Epoch: 03 | Train Loss: 0.680 | Train Acc: 56.08% |\n",
            "| Epoch: 04 | Train Loss: 0.673 | Train Acc: 60.62% |\n",
            "| Epoch: 05 | Train Loss: 0.669 | Train Acc: 61.98% |\n",
            "| Epoch: 06 | Train Loss: 0.668 | Train Acc: 60.13% |\n",
            "| Epoch: 07 | Train Loss: 0.668 | Train Acc: 59.92% |\n",
            "| Epoch: 08 | Train Loss: 0.656 | Train Acc: 62.01% |\n",
            "| Epoch: 09 | Train Loss: 0.639 | Train Acc: 63.86% |\n",
            "| Epoch: 10 | Train Loss: 0.634 | Train Acc: 65.25% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyMreksSOMOP",
        "outputId": "abfdfb24-87b4-4673-ef1b-60abcd0b0dd8"
      },
      "source": [
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in test_iterator:\n",
        "\n",
        "        predictions = model(batch.SentimentText).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.Sentiment)\n",
        "\n",
        "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "        correct = (rounded_preds == batch.Sentiment).float() \n",
        "        \n",
        "        acc = correct.sum()/len(correct)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "test_loss = epoch_loss / len(test_iterator)\n",
        "test_acc = epoch_acc / len(test_iterator)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.617 | Test Acc: 62.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZZfS1yFUixf",
        "outputId": "e6b98e2f-0f75-475d-c0a3-a0aa80da5a58"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "     \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.625 | Train Acc: 66.09% |\n",
            "| Epoch: 02 | Train Loss: 0.593 | Train Acc: 72.83% |\n",
            "| Epoch: 03 | Train Loss: 0.565 | Train Acc: 73.26% |\n",
            "| Epoch: 04 | Train Loss: 0.526 | Train Acc: 77.34% |\n",
            "| Epoch: 05 | Train Loss: 0.431 | Train Acc: 83.36% |\n",
            "| Epoch: 06 | Train Loss: 0.353 | Train Acc: 89.15% |\n",
            "| Epoch: 07 | Train Loss: 0.335 | Train Acc: 89.35% |\n",
            "| Epoch: 08 | Train Loss: 0.292 | Train Acc: 91.49% |\n",
            "| Epoch: 09 | Train Loss: 0.238 | Train Acc: 94.53% |\n",
            "| Epoch: 10 | Train Loss: 0.247 | Train Acc: 92.88% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6JYo3xWUCS0",
        "outputId": "53cc1b50-dc2d-423e-d340-5145389010d0"
      },
      "source": [
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in test_iterator:\n",
        "\n",
        "        predictions = model(batch.SentimentText).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.Sentiment)\n",
        "\n",
        "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "        correct = (rounded_preds == batch.Sentiment).float() \n",
        "        \n",
        "        acc = correct.sum()/len(correct)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "\n",
        "test_loss = epoch_loss / len(test_iterator)\n",
        "test_acc = epoch_acc / len(test_iterator)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.153 | Test Acc: 96.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyJjV8IVUnt_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}